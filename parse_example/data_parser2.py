import requests
from bs4 import BeautifulSoup
import pandas as pd


url = 'https://quotes.toscrape.com/'
response = requests.get(url)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∑–∞–ø—Ä–æ—Å –ø—Ä–æ—à—ë–ª —É—Å–ø–µ—à–Ω–æ
if response.status_code == 200:
    html = response.text
    print(f"‚úÖ HTML —Å–∫–∞—á–∞–Ω: {len(html)} —Å–∏–º–≤–æ–ª–æ–≤\n")
else:
    print(f"‚ùå –û—à–∏–±–∫–∞: {response.status_code}")
    exit()


soup = BeautifulSoup(html, 'html.parser')

# –ò—â–µ–º –≤—Å–µ —Ü–∏—Ç–∞—Ç—ã - —ç–ª–µ–º–µ–Ω—Ç—ã —Å –∫–ª–∞—Å—Å–æ–º 'quote'
quotes = soup.find_all('div', class_='quote')
print(f"–ù–∞–π–¥–µ–Ω–æ —Ü–∏—Ç–∞—Ç: {len(quotes)}\n")


data = []

for i, quote in enumerate(quotes, 1):
    # –¢–µ–∫—Å—Ç —Ü–∏—Ç–∞—Ç—ã 
    text_el = quote.find('span', class_='text')
    text = text_el.text.strip() if text_el else None
    
    # –ê–≤—Ç–æ—Ä 
    author_el = quote.find('small', class_='author')
    author = author_el.text.strip() if author_el else None
    
    # –¢–µ–≥–∏ 
    tags_el = quote.find_all('a', class_='tag')
    tags = ', '.join([tag.text.strip() for tag in tags_el]) if tags_el else None
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Å–ø–∏—Å–æ–∫
    data.append({
        '–Ω–æ–º–µ—Ä': i,
        '—Ü–∏—Ç–∞—Ç–∞': text,
        '–∞–≤—Ç–æ—Ä': author,
        '—Ç–µ–≥–∏': tags
    })
    
    print(f"{i}. {author}: {text[:50]}...")  # –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ 50 —Å–∏–º–≤–æ–ª–æ–≤


df = pd.DataFrame(data)

print(f"\n‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω!")
print(f"–°–æ–±—Ä–∞–Ω–æ —Ü–∏—Ç–∞—Ç: {len(df)}\n")


print("–ü–µ—Ä–≤—ã–µ 5 —Ü–∏—Ç–∞—Ç:\n")
print(df.head())

output_file = 'quotes.csv'

df.to_csv(output_file, index=False, encoding='utf-8-sig')
print(f"\n‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")

# === –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===
print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
print(f"–í—Å–µ–≥–æ —Ü–∏—Ç–∞—Ç: {len(df)}")
print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤: {df['–∞–≤—Ç–æ—Ä'].nunique()}")
print(f"–¶–∏—Ç–∞—Ç —Å —Ç–µ–≥–∞–º–∏: {df['—Ç–µ–≥–∏'].notna().sum()}")
